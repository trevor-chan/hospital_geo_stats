{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'singular': 'ignore',\n",
       " 'underflow': 'ignore',\n",
       " 'overflow': 'ignore',\n",
       " 'slow': 'ignore',\n",
       " 'loss': 'ignore',\n",
       " 'no_result': 'ignore',\n",
       " 'domain': 'ignore',\n",
       " 'arg': 'ignore',\n",
       " 'other': 'ignore'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "import statistics \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "\n",
    "np.seterr(all='raise')\n",
    "scipy.special.seterr(all='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#health insurance\n",
    "total = pd.read_csv('census_csv/2020_health_insurance_tract/total_insured/ACSST5Y2020.S2701_data_with_overlays_2022-04-17T005316.csv')\n",
    "percent_total_insured = total[['GEO_ID', 'S2701_C03_001E']] #Estimate!!Percent Insured!!Civilian noninstitutionalized population\n",
    "\n",
    "public = pd.read_csv('census_csv/2020_health_insurance_tract/public_insured/ACSST5Y2020.S2704_data_with_overlays_2022-04-17T113141.csv')\n",
    "percent_public_insured = public[['GEO_ID', 'S2704_C03_001E']] #Estimate!!Percent Public Coverage!!Civilian noninstitutionalized population\n",
    "\n",
    "private = pd.read_csv('census_csv/2020_health_insurance_tract/private_insured/ACSST5Y2020.S2703_data_with_overlays_2022-04-17T113149.csv')\n",
    "percent_private_insured = private[['GEO_ID', 'S2703_C03_001E']] #Estimate!!Percent Private Coverage!!Civilian noninstitutionalized population\n",
    "\n",
    "\n",
    "#race\n",
    "total_race = pd.read_csv('census_csv/2020_race_tract/DECENNIALPL2020.P1_data_with_overlays_2021-12-03T110422.csv')\n",
    "total_race_df = total_race[['GEO_ID', 'P1_001N']] #!!Total:!!Population of one race:\n",
    "\n",
    "white = pd.read_csv('census_csv/2020_race_tract/DECENNIALPL2020.P1_data_with_overlays_2021-12-03T110422.csv')\n",
    "white_race_df = white[['GEO_ID', 'P1_003N']] #!!Total:!!Population of one race:!!White alone\n",
    "\n",
    "black = pd.read_csv('census_csv/2020_race_tract/DECENNIALPL2020.P1_data_with_overlays_2021-12-03T110422.csv')\n",
    "black_race_df = black[['GEO_ID', 'P1_004N']] #!!Total:!!Population of one race:!!Black or African American alone\n",
    "\n",
    "amin = pd.read_csv('census_csv/2020_race_tract/DECENNIALPL2020.P1_data_with_overlays_2021-12-03T110422.csv')\n",
    "amin_race_df = amin[['GEO_ID', 'P1_005N']] #!!Total:!!Population of one race:!!American Indian and Alaska Native alone\n",
    "\n",
    "asian = pd.read_csv('census_csv/2020_race_tract/DECENNIALPL2020.P1_data_with_overlays_2021-12-03T110422.csv')\n",
    "asian_race_df = asian[['GEO_ID', 'P1_006N']] #!!Total:!!Population of one race:!!Asian alone\n",
    "\n",
    "nhpi = pd.read_csv('census_csv/2020_race_tract/DECENNIALPL2020.P1_data_with_overlays_2021-12-03T110422.csv')\n",
    "nhpi_race_df = nhpi[['GEO_ID', 'P1_007N']] #!!Total:!!Population of one race:!!Native Hawaiian and Other Pacific Islander alone\n",
    "\n",
    "\n",
    "#income\n",
    "median_income = pd.read_csv('census_csv/2020_income_tract/ACSST5Y2020.S1901_data_with_overlays_2022-04-05T131717.csv')\n",
    "median_income_df = median_income[['GEO_ID', 'S1901_C01_012E']] #Estimate!!Households!!Median income (dollars)\n",
    "\n",
    "#education\n",
    "education = pd.read_csv('census_csv/2020_education_tract/ACSST5Y2020.S1501_data_with_overlays_2022-04-18T160848.csv')\n",
    "education_df = education[['GEO_ID', 'S1501_C01_015E']] #Estimate!!Total!!AGE BY EDUCATIONAL ATTAINMENT!!Population 25 years and over!!Bachelor's degree or higher\n",
    "\n",
    "\n",
    "comprehensive = pd.merge(percent_total_insured, percent_public_insured, on='GEO_ID')\n",
    "comprehensive = pd.merge(comprehensive, percent_private_insured, on='GEO_ID')\n",
    "\n",
    "comprehensive = pd.merge(comprehensive, total_race_df, on='GEO_ID')\n",
    "comprehensive = pd.merge(comprehensive, white_race_df, on='GEO_ID')\n",
    "comprehensive = pd.merge(comprehensive, black_race_df, on='GEO_ID')\n",
    "comprehensive = pd.merge(comprehensive, amin_race_df, on='GEO_ID')\n",
    "comprehensive = pd.merge(comprehensive, asian_race_df, on='GEO_ID')\n",
    "comprehensive = pd.merge(comprehensive, nhpi_race_df, on='GEO_ID')\n",
    "comprehensive = pd.merge(comprehensive, median_income_df, on='GEO_ID')\n",
    "comprehensive = pd.merge(comprehensive, education_df, on='GEO_ID')\n",
    "\n",
    "tag = comprehensive.iloc[0]\n",
    "comprehensive = comprehensive.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehensive['P1_003N'] = comprehensive['P1_003N'].astype(int)/comprehensive['P1_001N'].astype(int)*100\n",
    "comprehensive['P1_004N'] = comprehensive['P1_004N'].astype(int)/comprehensive['P1_001N'].astype(int)*100\n",
    "comprehensive['P1_005N'] = comprehensive['P1_005N'].astype(int)/comprehensive['P1_001N'].astype(int)*100\n",
    "comprehensive['P1_006N'] = comprehensive['P1_006N'].astype(int)/comprehensive['P1_001N'].astype(int)*100\n",
    "comprehensive['P1_007N'] = comprehensive['P1_007N'].astype(int)/comprehensive['P1_001N'].astype(int)*100\n",
    "comprehensive['S1501_C01_015E'] = comprehensive['S1501_C01_015E'].astype(int)/comprehensive['P1_001N'].astype(int)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehensive['GEO_ID'] = comprehensive['GEO_ID'].apply(lambda x: x.replace('1400000US',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "result = comprehensive.to_json(path_or_buf='maps/Map/census_data.json', orient='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEO_ID</th>\n",
       "      <th>S2701_C03_001E</th>\n",
       "      <th>S2704_C03_001E</th>\n",
       "      <th>S2703_C03_001E</th>\n",
       "      <th>P1_001N</th>\n",
       "      <th>P1_003N</th>\n",
       "      <th>P1_004N</th>\n",
       "      <th>P1_005N</th>\n",
       "      <th>P1_006N</th>\n",
       "      <th>P1_007N</th>\n",
       "      <th>S1901_C01_012E</th>\n",
       "      <th>S1501_C01_015E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42101000101</td>\n",
       "      <td>96.5</td>\n",
       "      <td>15.3</td>\n",
       "      <td>92.5</td>\n",
       "      <td>2329</td>\n",
       "      <td>78.531559</td>\n",
       "      <td>4.594246</td>\n",
       "      <td>0.171748</td>\n",
       "      <td>8.630313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>104458</td>\n",
       "      <td>67.196222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42101000102</td>\n",
       "      <td>93.2</td>\n",
       "      <td>11.6</td>\n",
       "      <td>89.3</td>\n",
       "      <td>3511</td>\n",
       "      <td>78.610083</td>\n",
       "      <td>4.158359</td>\n",
       "      <td>0.170891</td>\n",
       "      <td>8.259755</td>\n",
       "      <td>0.028482</td>\n",
       "      <td>104236</td>\n",
       "      <td>59.384791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42101000200</td>\n",
       "      <td>92.3</td>\n",
       "      <td>30.7</td>\n",
       "      <td>70.2</td>\n",
       "      <td>3367</td>\n",
       "      <td>24.888625</td>\n",
       "      <td>7.692308</td>\n",
       "      <td>0.207900</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>83854</td>\n",
       "      <td>37.689338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42101000300</td>\n",
       "      <td>98.6</td>\n",
       "      <td>26.2</td>\n",
       "      <td>89.7</td>\n",
       "      <td>4501</td>\n",
       "      <td>70.562097</td>\n",
       "      <td>7.065097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.374583</td>\n",
       "      <td>0.066652</td>\n",
       "      <td>84843</td>\n",
       "      <td>53.365919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42101000401</td>\n",
       "      <td>97.1</td>\n",
       "      <td>22.9</td>\n",
       "      <td>84.5</td>\n",
       "      <td>3123</td>\n",
       "      <td>57.028498</td>\n",
       "      <td>8.229267</td>\n",
       "      <td>0.192123</td>\n",
       "      <td>25.488313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73438</td>\n",
       "      <td>60.166507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>42101980905</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>42101980906</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>42101989100</td>\n",
       "      <td>81.1</td>\n",
       "      <td>81.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3688</td>\n",
       "      <td>8.920824</td>\n",
       "      <td>73.291757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.840564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>0.379610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>42101989200</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>42101989300</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>65</td>\n",
       "      <td>36.923077</td>\n",
       "      <td>30.769231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.538462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>408 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          GEO_ID S2701_C03_001E S2704_C03_001E S2703_C03_001E P1_001N  \\\n",
       "1    42101000101           96.5           15.3           92.5    2329   \n",
       "2    42101000102           93.2           11.6           89.3    3511   \n",
       "3    42101000200           92.3           30.7           70.2    3367   \n",
       "4    42101000300           98.6           26.2           89.7    4501   \n",
       "5    42101000401           97.1           22.9           84.5    3123   \n",
       "..           ...            ...            ...            ...     ...   \n",
       "404  42101980905              -              -              -       0   \n",
       "405  42101980906              -              -              -       0   \n",
       "406  42101989100           81.1           81.1            0.0    3688   \n",
       "407  42101989200              -              -              -       3   \n",
       "408  42101989300              -              -              -      65   \n",
       "\n",
       "       P1_003N    P1_004N   P1_005N    P1_006N   P1_007N S1901_C01_012E  \\\n",
       "1    78.531559   4.594246  0.171748   8.630313  0.000000         104458   \n",
       "2    78.610083   4.158359  0.170891   8.259755  0.028482         104236   \n",
       "3    24.888625   7.692308  0.207900  61.538462  0.000000          83854   \n",
       "4    70.562097   7.065097  0.000000  14.374583  0.066652          84843   \n",
       "5    57.028498   8.229267  0.192123  25.488313  0.000000          73438   \n",
       "..         ...        ...       ...        ...       ...            ...   \n",
       "404        NaN        NaN       NaN        NaN       NaN              -   \n",
       "405        NaN        NaN       NaN        NaN       NaN              -   \n",
       "406   8.920824  73.291757  0.000000   0.840564  0.000000              -   \n",
       "407  33.333333  66.666667  0.000000   0.000000  0.000000              -   \n",
       "408  36.923077  30.769231  0.000000   1.538462  0.000000              -   \n",
       "\n",
       "     S1501_C01_015E  \n",
       "1         67.196222  \n",
       "2         59.384791  \n",
       "3         37.689338  \n",
       "4         53.365919  \n",
       "5         60.166507  \n",
       "..              ...  \n",
       "404             NaN  \n",
       "405             NaN  \n",
       "406        0.379610  \n",
       "407        0.000000  \n",
       "408        0.000000  \n",
       "\n",
       "[408 rows x 12 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comprehensive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = json.load(open('maps/new_map/tracts_topo.json'))\n",
    "\n",
    "newgeolist = []\n",
    "count = 0\n",
    "for item in data['objects']['tl_2020_42_tract']['geometries']:\n",
    "    if item['properties']['COUNTYFP'] == '101':\n",
    "        newgeolist.append(item)\n",
    "        \n",
    "data['objects']['tl_2020_42_tract']['geometries'] = newgeolist\n",
    "\n",
    "with open('maps/new_map/tracts_topo.json', 'w') as fp:\n",
    "    json.dump(data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
